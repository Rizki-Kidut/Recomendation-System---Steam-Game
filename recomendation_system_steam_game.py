# -*- coding: utf-8 -*-
"""Copy of Recomendation System - Steam Game.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KTT6TvfAI561A3NVjF5AFdWkDk070Etw

# Recomendation System Submission - Steam Game Recomendation

##1. *Import Dataset*

Untuk proyek ini, digunakan dua dataset yang berbeda. Keduannya tersedia gratis di *Kaggle* dan data diekstrak dari *Steam*. *Dataset* diimport menggunakan *Kaggle API*. Dataset tersebut adalah *User Dataset* dan *Game Dataset*.

###a. *User Dataset*
*Dataset* yang pertama adalah *user dataset*. *Dataset* terdiri dari kolom:
- ***User*** : *user id* dalam format numerik,
- ***Game*** : Nama *game*,
- ***Purchase_play*** : Perilaku dari user terhadap game tersebut apakah *purchase* ketika *user* membenli *game* tersebut atau *play* ketika *user* memainkannya dan
- ***hrs*** : Jumlah nilai sesuai dengan perilaku. Jika perilaku *play* nilai ini merepresentasikan jumlah jam *game* tersebut dimainkan. Jika perilaku *purchase* nilai ini bernilai 1.

Setiap baris dari dataset mewakili perilaku pengguna terhadap sebuah game, baik '*play*' atau '*purchase*'. Jika perilakunya adalah '*play*', nilai yang terkait dengannya sesuai dengan jumlah jam bermain. Jika perilakunya adalah '*purchase*', nilai yang terkait dengannya adalah 1, yang berarti pengguna membeli game tersebut. Dalam kasus dataset pengguna ini, nilai yang terkait dengan '*purchase*' selalu 1.


*Link Dataset User* : [*user*](https://www.kaggle.com/datasets/tamber/steam-video-games)

###b. Game Dataset
*Dataset* kedua adalah *game dataset*. Terdiri dari:
- ***url :*** *link url* (mengarah langsung ke *Steam store*)
- ***types :*** Tipe dari paket game (*app, bundle, other*)
- ***name:*** Judul *Game*
- ***desc_snippet:*** Deskripsi singkat dari *game*
- ***recent reviews:*** Ulasan terbaru
- ***all reviews:*** Seluruh ulasan
- ***release date:*** Tanggal *game* dirilis
- ***developer:*** Pengembang *game* / pembuat *game*
- ***publisher:*** Perusahaan penerbit *game*
- ***popular tags:*** *Tag* yang populer pada *game* (*Gore, Action, Shooter, PvP, Other*)
- ***game detail:*** Informasi detail dari *game* (*Multi-player, Single-player, Full controller support, other*)
- ***languages:*** Bahasa yang didukung oleh *game*
- ***achievements:*** Pencapaian yang terdapat dalam *game*
- ***genre:*** Jenis *genre* dari *game* (*Action, Adventure, RPG, Strategy, other*)
- ***game description:*** Deskripsi lengkap dari *game*
- ***description of mature content:*** Deskripsi dari konten dewasa dalam *game*
- ***minimum requirement to run the game:*** Spesifikasi minimal untuk menjalankan *game*
- ***recommended requirement:*** Spesifikasi rekomendasi untuk menjalankan *game* dalam kondisi optimalnya
- ***original price:*** Harga game asli
- ***price with discount:*** Harga game setelah *discount*

Secara total terdapat 51920 *game* dalam dataset.



*Link dataset Game* : [*game*](https://www.kaggle.com/datasets/trolukovich/steam-games-complete-dataset)
"""

! pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d tamber/steam-video-games

!kaggle datasets download -d trolukovich/steam-games-complete-dataset

import os
import zipfile
local_zip_1= '/content/steam-video-games.zip'
local_zip_2= '/content/steam-games-complete-dataset.zip'
zip_ref_1 = zipfile.ZipFile(local_zip_1, 'r')
zip_ref_2 = zipfile.ZipFile(local_zip_2, 'r')
zip_ref_1.extractall('/content')
zip_ref_2.extractall('/content')
zip_ref_1.close()
zip_ref_2.close()

"""##2. *Load Dataset*

###a. *User Dataset*

Sebagian dari *user dataset* ditampilkan dalam tabel di bawah ini. Perlu dicatat bahwa dataset asli tidak memiliki tajuk, dan yang ditampilkan dalam tabel di bawah ini ditambahkan untuk kenyamanan berdasarkan deskripsi data.
"""

import pandas as pd

users = pd.read_csv('steam-200k.csv', header=None, names=['user', 'game', 'purchase_play', 'hrs', 'tmp'])
users.head(10)

users.info()

user_unique_value = users['user'].nunique()
game_unique_value = users['game'].nunique()

print("Total user unique value are ", user_unique_value)
print("Total game unique value are ", game_unique_value)

"""*User dataset* berisi total 200.000 baris, termasuk 5.155 game dan 12.393 pengguna . Demi kenyamanan, sruktur *dataset* diformat ulang dengan memisahkan informasi yang tersimpan dalam kolom 'perilaku' menjadi dua kolom: '*purchase*' dan '*play*'. Untuk setiap baris, kolom '*play*' memiliki nilai 1 jika pengguna benar-benar memainkan game atau 0 jika pengguna tidak memiliki catatan jam bermain."""

users.describe()

"""Dari info statistik pada colomn *hrs*, nilai maksimalnya adalah 11.754 jam dengan nilai minimal 1 jam dan nilai rata-rata 17.87 jam.

Karena colomn *temp* hanya memiliki nilai 0, maka colomn ini akan di-*drop*
"""

users.drop('tmp', inplace=True, axis=1)

users.head()

"""Setiap baris dalam *user dataset* yang diformat ulang mewakili sebuah interaksi pengguna yang unik. Sebagian dari dataset pengguna yang diformat ulang ditampilkan dalam tabel di bawah ini."""

users['purchase'] = users['purchase_play'] == 'purchase'
users['purchase'] = users['purchase'].astype(int)
users['play'] = users['purchase_play'] == 'play'
users['play'] = users['play'].astype(int)
users['hrs'] = users['hrs'] - users['purchase']
users = users.groupby(by=['user', 'game']).agg({'hrs': 'sum', 'purchase': 'sum', 'play': 'sum'}).reset_index()

users_filter = users[users['user'] == 151603712].sort_values(by='hrs', ascending=False)
users_filter.head(5)

users.info()

"""Total data setelah diformat ulang adalah 128.804 data"""

users.describe()

"""Informasi ststistik dari dataset setelah diformat ulang, untuk kolom *hrs* rata rata jam bermain adalah 26.75 jam dengan maksmilam jam bermain masih sama yaitu 11.754 jam

###b. *Game Dataset*

Dataset kedua adalah *game dataset*. IDataset ini berisi daftar *game*, deskripsinya, url (diarahkan ke toko *Steam*), jenis paket(*app, bundle*), judul *game*, deskripsi singkat, ulasan terbaru, semua ulasan, tanggal rilis, pengembang, penerbit, tag populer(*Gore, Action, Shooter, PvP…*), detail *game* (*Multi-player, Single-player, Full controller support…*), bahasa, pencapaian, genre (*Action, Adventure, RPG, Strategy…*), deskripsi *game*, deskripsi konten dewasa, persyaratan minimum untuk menjalankan *game*, persyaratan yang disarankan, harga asli dan harga dengan diskon.
"""

game = pd.read_csv('steam_games.csv')
game.head(10)

game.info()

"""Terdapat 40.817 *game* dalam *dataset* ini. Jika melihat jumlah *non-null* , dapat disimpulkan *dataset* ini memiliki banyak *missing-values*.

##3. *Univariate Exploratory Data Analysis*

###a. *User  Dataset*

Untuk mengetahui apakah *game* yang paling banyak dibeli sesuai dengan *game* yang paling banyak dimainkan. Untuk setiap *game*, jumlah total pengguna dan total waktu *game* dimainkan oleh semua pengguna dihitung. Hasilnya ditampilkan pada tabel di bawah ini dalam urutan menurun berdasarkan jumlah pengguna. Tabel dibuat untuk 20 *game* teratas dengan pengguna terbanyak.
"""

game_freq = users.groupby(by='game').agg({'user': 'count', 'hrs': 'sum'}).reset_index()
top20 = game_freq.sort_values(by='user',ascending=False)[:20].reset_index()
top20['hrs']=top20['hrs'].round(1)
top20

"""Dari tabel di atas, untuk beberapa *game*, ada hubungan antara yang paling banyak dimainkan dan yang paling banyak dibeli. Sebagai contoh, '*Dota 2*' tidak dapat disangkal lagi merupakan *game* yang paling populer, memiliki jumlah pengguna terbanyak dan total jam bermain terbanyak. Namun, hal ini tidak selalu terjadi, contoh yang menarik adalah '*Half-Life 2 Lost Coast*' yang memiliki jumlah pengguna yang tinggi (981 pengguna), tetapi total jam bermainnya cukup rendah (184,4 jam). Penjelasan yang mungkin untuk hal ini adalah karena game ini dibeli sebagai bagian dari bundel game.

Untuk memvisualisasikan hasil yang ditampilkan pada tabel di atas dengan lebih baik, *plot histogram* digunakan. Judul *game* diurutkan dalam urutan menurun berdasarkan jumlah pengguna. Gradien warna menunjukkan total jam bermain, dari yang paling banyak dimainkan hingga yang paling sedikit dimainkan.
"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(20, 10))
sns.set(font_scale = 2)
ax = sns.barplot(x='user', y='game', hue='hrs',alpha=0.9,data=top20, palette='Blues_r',dodge=False)
ax.set(xlabel='Jumlah Pengguna', ylabel='Game', title='20 game dengan Pengguna terbanyak')
ax.set_xticks(ax.get_xticks())
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
ax.legend(fontsize=13)

plt.savefig('histogram_game with most users.png')
plt.show()

"""Untuk beberapa kasus, tidak ada hubungan antara jumlah total pengguna dan total jam yang dimainkan, yang berarti bahwa jumlah pengguna yang tinggi tidak merepresentasikan jumlah jam yang tinggi pula.

Jenis plot yang sama dibuat ulang, tetapi kali ini hanya mempertimbangkan pengguna yang benar-benar memainkan *game*. Jadi, untuk setiap game, pengguna yang membelinya tetapi tidak pernah memainkannya dihapus.
"""

index=users[users['play']==0].index
users.drop(index,inplace=True)
game_total_hrs = users.groupby(by='game')['hrs'].sum()
most_played_games = game_total_hrs.sort_values(ascending=False)[:20]

# Game dengan jumlah pengguna terbanyak
game_freq = users.groupby(by='game').agg({'user': 'count', 'hrs': 'sum'}).reset_index()
top20 = game_freq.sort_values(by='user',ascending=False)[:20].reset_index()
top20['hrs']=top20['hrs'].round(1)

plt.figure(figsize=(20, 10))
sns.set(font_scale = 2)
ax = sns.barplot(x='user', y='game', hue='hrs',alpha=0.9,data=top20, palette='Blues_r',dodge=False)
ax.set(xlabel='Jumlah pengguna', ylabel='Game', title='20 game dengan Pengguna terbanyak (Dimainkan)')
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
ax.legend(fontsize=13)

plt.savefig('histogram_game with most users(play).png')
plt.show()

"""Ketika membandingkan plot baru ini dengan plot sebelumnya, beberapa *game* jatuh dari 20 *game*teratas berdasarkan jumlah pengguna. Sebagai contoh '*Counter-Strike Condition Zero*', yang berada di posisi 15 teratas dalam plot dengan mempertimbangkan semua pengguna yang membeli *game* tersebut, tidak muncul di 20 *game* teratas dengan mempertimbangkan hanya pengguna yang benar-benar memainkan *game* tersebut. Contoh yang berlawanan adalah '*Terraria*' yang muncul di plot kedua sebagai 11 teratas sementara tidak terdaftar di plot pertama. Seperti yang telah disebutkan sebelumnya, penjelasan yang mungkin untuk perbedaan ini adalah beberapa *game* dibeli sebagai bagian dari bundel *game*.

###b. *Game Dataset*

Untuk memahami lebih baik bagaimana ulasan *game* didistribusikan, jumlah *game* dengan persentase ulasan positif masing-masing diplot.
"""

import re
import pathlib

# menambah dan menginisialisasi kolom baru
game["review_qualification"] = ""
game["percentage_positive_review"] = -1

for i, row in game.iterrows():
    if type(row["all_reviews"]) == str:

        # ekstrak % dari ulasan positif
        x = re.findall(r'- [0,1,2,3,4,5,6,7,8,9]*%', row["all_reviews"])
        if len(x) != 0:
            game.at[i, 'percentage_positive_review'] = x[0].translate({ord(i): None for i in '- %'})

        # ekstrak kualifikasi ulasan
        reviewParse = row["all_reviews"].split(",")
        if 'user reviews' in reviewParse[0]:
            game.at[i, 'review_qualification'] = ""
        else:
            game.at[i, 'review_qualification'] = reviewParse[0]

# Daftar dari kemungkinan kualifikasi ulasan
possibleReview =game["review_qualification"].unique()
print(possibleReview)


# Cetak csv ulasan
game.to_csv(pathlib.Path(r'/content/steam_games_reviews.csv'),
                 columns=["name", "percentage_positive_review", "review_qualification", "all_reviews"],
                 index=False)

reviews = pd.read_csv("steam_games_reviews.csv")
reviews

dataReviews = pd.read_csv("steam_games_reviews.csv", usecols=["name", "percentage_positive_review"],)
sns.set(font_scale = 1)
plt.hist(x=dataReviews["percentage_positive_review"], range=[0, 100], bins=80)

# Tambah judul dan nama axis
plt.title('Distribusi Ulasan Game')
plt.ylabel('Jumlah Game')
plt.xlabel('Rating %')

plt.savefig('Distribution of Game Reviews.png')
plt.show()

"""Dari plot distribusi diatas terlihat jelas bahwa nilai ulasan untuk *game* dalam *game dataset* terkonsentrasi pada nilai rating 60-100%.

Hal ini mengindikasikan bahwa kebanyakan *game* mendapatkan ulasan yang cukup baik dari pengguna.

Plot di bawah ini mencantumkan semua genre game yang tersedia di dataset game dengan jumlah game masing-masing.
"""

x = []

for i, row in game.iterrows():
    if type(row["genre"]) is str:
        x = x + row["genre"].split(',')

uniqueGenre = list(set(x))

df = pd.DataFrame(columns=["genre", "count"])
for genre in uniqueGenre:
    df2 = pd.DataFrame(data=[[genre, x.count(genre)]], columns=["genre", "count"])
    df = pd.concat([df, df2], ignore_index=True)

df = df.sort_values(by="count", ascending=False)

ax = df.plot.barh(x='genre', y='count')

# Tanbah judul dan nama axis
plt.title('Pengulangan Genre')
plt.xlabel('Jumlah Game')
plt.ylabel('Genre')
plt.yticks(fontsize=6)


plt.savefig('Recurrence of Genre.png')
plt.show()

"""Berdasarkan plot diatas, 5 genre terbanyak dalam *dataset* adalah *Indie, Action, Adventure, Casual,* dan *Simulation*. Hal ini mengindikasikan *game Action, Adventure* masih menjadi primadona dimata para pecinta *game* pada *Steam Store*

Plot serupa dibuat, menunjukkan 20 tag game terpopuler yang tersedia di dataset game dengan jumlah game masing-masing.
"""

x = []

for i, row in game.iterrows():
    if type(row["popular_tags"]) is str:
        x = x + row["popular_tags"].split(',')

uniqueGenre = list(set(x))

df = pd.DataFrame(columns=["popular_tags", "count"])
for genre in uniqueGenre:
    df2 = pd.DataFrame(data=[[genre, x.count(genre)]], columns=["popular_tags", "count"])
    df = pd.concat([df, df2], ignore_index=True)

df = df.sort_values(by="count", ascending=False)
print(df)
df = df.head(20)

ax = df.plot.barh(x='popular_tags', y='count')

# Tanbah judul dan nama axis
plt.title('Pengulangan Tag Populer')
plt.xlabel('Jumlah Game')
plt.ylabel('Tag Populer')
plt.yticks(fontsize=6)

plt.savefig('Recurrence of Popular Tags.png')
plt.show()

"""Terakhir, plot berikut ini menunjukkan 20 detail *game* yang paling sering muncul di *dataset game* dengan jumlah *game* yang terkait dengan masing-masing detail *game*.

Hasil yang ditunjukkan pada plot *popular tag* serupa dengan hasil pada plot *genre*. Dimana hasil 5 *popular tag* adalah *Indie, Action, Adventure, Casual, dan Simulation*

##4. *Data Preprocessing*

Untuk membangun sistem rekomendasi, data perlu disiapkan dan membangun algoritmanya. Untuk melakukannya, pertama-tama perlu dilakukan praproses pada dataset game.

###a. Pilih informasi yang berguna
Untuk menyiapkan data untuk rekomendasi berbasis konten, langkah pertama adalah memilih informasi yang paling berguna untuk menemukan game yang serupa. Kolom-kolom yang berguna dari dataset game dengan menggunakan kode berikut.
"""

select_game = game.loc[:, ["name", "genre", "game_details", "popular_tags"]]
select_game.head()

select_game.info()

"""There are 40.833 entries in select_game

##b. *Missing values*
"""

select_game.isnull().sum()

"""Ada banyak *missing values* dari semua kolom, kolom "*popular tag*" adalah kolom dengan nilai yang paling banyak hilang dengan 2.945 nilai yang hilang"""

import missingno as msno

# Untuk visualisasi missing values pada dataset;

sorted = select_game.sort_values('name')
msno.matrix(sorted)

plt.savefig('missing_data_matrix.png')
plt.show()

"""Nilai yang hilang pada data divisualisasikan menggunakan matriks msno.
Karena dapat mengganggu hasil model, maka *missing values* tersebut dihilangkan
"""

select_game = select_game.dropna()

select_game.isnull().sum()

"""Setelah *missing values* dihilangkan, jumlah *missing values* sudah menjadi 0 untuk setiap kolom

###c. Filter data dari kedua *Dataset*

Diputuskan untuk hanya menyimpan game yang ada di *game dataset* dan *user dataset*. Hal ini dipilih karena ada banyak game dalam dataset game yang belum pernah dimainkan atau dibeli oleh pengguna mana pun dalam dataset pengguna, sehingga tidak ada gunanya mempertimbangkannya dalam sistem rekomendasi. Selain itu, dataset game terlalu besar untuk membuat *matrix cosine similarity* karena membutuhkan terlalu banyak memori.

Untuk mencocokkan *game* dari kedua dataset secara bersamaan, ID untuk setiap *game* dibuat dengan menghapus semua simbol non-alfanumerik dan spasi, dan mengubah semua huruf kapital menjadi huruf kecil dengan menggunakan kode berikut ini, hal yang sama juga dilakukan untuk *game-game* yang ada di *user dataset*.
"""

# Buat kolom ID untuk game dan user dataset
select_game["ID"] = ""
users["ID"] = ""

# hapus spasi dan karakter khusus dari nama game di kedua set data
for i, row in select_game.iterrows():
    clean = re.sub('[^A-Za-z0-9]+', '', row["name"])
    clean = clean.lower()
    select_game.at[i, 'ID'] = clean

for i, row in users.iterrows():
    clean = re.sub('[^A-Za-z0-9]+', '', row["game"])
    clean = clean.lower()
    users.at[i, 'ID'] = clean

select_game.head()

users.head()

"""Setelah itu, semua ID unik dari *user dataset* digunakan untuk memfilter baris di *game dataset*, dan menampilkan nilai ID yang sama dari kedua dataset"""

# temukan semua game di game dataset yang cocok dengan game di user dataset
gameArrayUsers = users["ID"].unique()
print(len(gameArrayUsers))
criteriaTest = select_game['ID'].isin(gameArrayUsers)
usedGames = select_game[criteriaTest]
print(len(usedGames))

usedGames

usedGames.info()

"""Hasilnya, diperoleh 2.297 *game* dari *game dataset* yang cocok dengan 3.598 *game* dari *user dataset*.

##5. *Model Development*
###a. *Content Based Filtering*

####- *TF-IDF Vectorizer based on genre*

Fitur penting pada kolom genre diekstrak menggunakan *TF-IDF Vectorizer* menggunakan fungsi *tfidfvectorizer()* dari library sklearn
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()

tf.fit(usedGames['genre'])

tf.get_feature_names_out()

"""Hasil dari ekstraksi tersebut, dilakukan *fit* dan transformasi kedalam bentuk matriks"""

tfidf_matrix_genre = tf.fit_transform(usedGames['genre'])

tfidf_matrix_genre.shape

tfidf_matrix_genre.todense()

"""Untuk menghasilkan vektor tf-idf dalam bentuk matriks, kita menggunakan fungsi *todense()*"""

pd.DataFrame(
    tfidf_matrix_genre.todense(),
    columns=tf.get_feature_names_out(),
    index=usedGames.name
).sample(22, axis=1, random_state=42).sample(10, axis=0, random_state=42)

"""Dari matriks TF-IDF diatas terlihat bahwa *Grand Theft Auto V* termasuk kedalam *genre* *Adventure* dengan nilai 0.7832 dan *Action* dengan nilai 0.6217. Sedangkan, *Planetbase* termasuk kedalam *genre* *simulation* dengan nilai 0.6937, *strategy* dengan nilai 0.5859, dan *Indie* dengan nilai 0.4188

####- Cosine Similiarity based on genre

Derajat kesamaan (*similarity degree*) antar *game based on genre* dihitung dengan teknik *cosine similarity* menggunakan fungsi *cosine_similarity* dari library sklearn.
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim_genre = cosine_similarity(tfidf_matrix_genre)
cosine_sim_genre

cosine_sim_genre_df = pd.DataFrame(cosine_sim_genre, index=usedGames['name'], columns=usedGames['name'])
print('Shape:', cosine_sim_genre_df.shape)

cosine_sim_genre_df.sample(10, axis=1, random_state=42).sample(10, axis=0, random_state=50)

"""*Matriks cosine similarity* diatas memiliki ukuran 2.297 x 2.297 game. Sebagai contoh ditampilkan 10 *game* pada baris vertikal dan 10 *game* pada baris horizontal.

Dari matriks *Cosine similarity* diatas dapat diketahui bahwa *game Call of Duty: United Offensive* memiliki kesamaan dengan beberapa *game* seperti *Grand Theft Auto V, Castlevania: Lords of Shadow – Mirror of Fate HD,* dan *Collapse* dengan nilai *similarity* yang sama yaitu 0.6216, dan *Axiom Verge* dengan nilai similarity 0.5318

####- Rekomendasi berdasarkan genre
"""

def game_recommendations_genre(game_name, similarity_data=cosine_sim_genre_df, items=usedGames[['name', 'genre']], k=5):

    index = similarity_data.loc[:,game_name].to_numpy().argpartition(
        range(-1, -k, -1))


    closest = similarity_data.columns[index[-1:-(k+2):-1]]


    closest = closest.drop(game_name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Setelah *Matriks cosine similarity* dibuat, selanjutnya dibuatkan rekomendasi *game* berdasarkan genre. Sebagai contoh akan dibuatkan rekomendasi untuk game *Portal 2*."""

usedGames[usedGames.name.eq('Portal 2')]

"""Game *Portal 2* ini memiliki genre *Action* dan *Adventure*"""

game_recommendations_genre('Portal 2')

"""Hasil rekomendasi untuk game *Portal 2* pada tabel di atas memiliki genre yang sama yaitu *Action* dan *Adventure*

####- Rekomendasi berdasarkan *popular tags*

Selain membuat Rekomendasi berdasarkan *genre* dibuatkan juga rekomendari berdasarkan *popular tags*.
"""

tf = TfidfVectorizer()
tf.fit(usedGames['popular_tags'])

tfidf_matrix_tags = tf.fit_transform(usedGames['popular_tags'])

# Menghitung cosine similarity berdasarkan popular tags pada matrix tf-idf
cosine_sim_tags = cosine_similarity(tfidf_matrix_tags)
cosine_sim_tags

cosine_sim_tags_df = pd.DataFrame(cosine_sim_tags, index=usedGames['name'], columns=usedGames['name'])

def game_recommendations_tags(game_name, similarity_data=cosine_sim_tags_df, items=usedGames[['name', 'popular_tags']], k=5):

    index = similarity_data.loc[:,game_name].to_numpy().argpartition(
        range(-1, -k, -1))


    closest = similarity_data.columns[index[-1:-(k+2):-1]]


    closest = closest.drop(game_name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

game_recommendations_tags('Portal 2')

"""Hasil rekomendasi untuk game Portal 2 pada tabel di atas memiliki *popular tags* yang sama yaitu *Puzzle,Co-op,First-Person,Sci-fi,Comedy*

####- Rekomendasi berdasarkan *game details*

Selain membuat Rekomendasi berdasarkan *genre* dan *popular tags* dibuatkan juga rekomendari berdasarkan *game details*.
"""

tf = TfidfVectorizer()
tf.fit(usedGames['game_details'])

tfidf_matrix_detail = tf.fit_transform(usedGames['game_details'])

# Menghitung cosine similarity berdasarkan popular tags pada matrix tf-idf
cosine_sim_detail = cosine_similarity(tfidf_matrix_detail)
cosine_sim_detail

cosine_sim_detail_df = pd.DataFrame(cosine_sim_detail, index=usedGames['name'], columns=usedGames['name'])

def game_recommendations_detail(game_name, similarity_data=cosine_sim_detail_df, items=usedGames[['name', 'game_details']], k=5):

    index = similarity_data.loc[:,game_name].to_numpy().argpartition(
        range(-1, -k, -1))


    closest = similarity_data.columns[index[-1:-(k+2):-1]]


    closest = closest.drop(game_name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

game_recommendations_detail('Portal 2')

"""Tabel di atas menunjukkan rekomendasi *game* berdasarkan *game details*. Hasil rekomendasi untuk game Portal 2 pada tabel di atas memiliki *game details* yang sama yaitu *Single-player* dan *Steam Achievements*

###b. Collaborative Filtering

####- Data preparation

Sebelum melakukan *Collaborative Filtering*. *User dataset* dan *game dataset* harus dipersiapkan terlebih dahulu.
"""

data = users.copy()
data

"""Pada *User dataset* diatas kolom *purchase, play* dan *ID* tidak digunakan, maka ketiga kolom tersebut akan dihapuskan."""

data = data.drop(['purchase', 'play', 'ID'], axis=1)
data

"""Kolom *user dataset* tidak terdapat review atau *Explicit Feedback*. Data yang tersedia adalah Jam bermain, dimana data tersebut merupakan *Implicit Feedback*. Karena perbedaan nilai pada kolom Jam bermain cukup jauh, diputuskan untuk mengitung rata rata jam permainan dan mengkonversikan nilainya menjadi rating dengan nilai (0-5)."""

data['user'] = data['user'].astype(str)
averages = data.groupby(['game'], as_index=False).hrs.mean()
averages['avg_hrs'] = averages['hrs']
averages.drop('hrs', axis=1, inplace=True)
averages.head(10)

"""Tabel diatas menunjukkan hasil perhitungan rata - rata Jam permainan"""

import numpy as np

final_ratings = pd.merge(data,averages[['game','avg_hrs']],on='game')
conditions = [
    (final_ratings['hrs']>=0.8*final_ratings['avg_hrs']),
    (final_ratings['hrs']>=0.6*final_ratings['avg_hrs']) & (final_ratings['hrs']<0.8*final_ratings['avg_hrs']),
    (final_ratings['hrs']>=0.4*final_ratings['avg_hrs']) & (final_ratings['hrs']<0.6*final_ratings['avg_hrs']),
    (final_ratings['hrs']>=0.2*final_ratings['avg_hrs']) & (final_ratings['hrs']<0.4*final_ratings['avg_hrs']),
    final_ratings['hrs']>=0,
]
values = [5,4,3,2,1]
final_ratings['rating'] = np.select(conditions,values)
final_ratings

"""Tabel diatas menunjukkan hasil konversi ke jam permainan ke rating"""

final_ratings = final_ratings.drop(['hrs','avg_hrs'], axis=1)
final_ratings

"""Karena, data final_ratings belum memiliki identitas untuk *user* dan *game*. Maka dibuatkan kolom *user_id* dan *game_id*"""

final_ratings['user_id'] = final_ratings['user'].astype('category').cat.codes
final_ratings['game_id'] = final_ratings['game'].astype('category').cat.codes
final_ratings

"""Tabel diatas menunjukkan data *final_ratings* yang telah ditambahkan kolom *user_id* dan *game_id*.

Tahap selanjutnya adalah menambahkan kolom *game_id* ke data *UsedGames* agar terdapat hubungan antara kedua data tersebut

Karena judul kolom nama game di kedua dataset berbeda, menyamakan judul kolom di data *UsedGames*
"""

usedGames = usedGames.rename(columns={'name':'game'})
usedGames

"""Kolom *game_id* dari data *final_ratings* digabungkan dengan data *usedGames* menggunakan pendekatan *inner join*. Hasil penggabungan keduanya diberi nama data *game*"""

game = usedGames.merge(final_ratings[['game','game_id']], on='game', how='inner')

game

"""Dibuatkan dataset baru *game_new* yang berisikan *game_id*, *game* dan *genre* dari data *game*"""

game_ids = game['game_id'].tolist()

game_name = game['game'].tolist()

game_genre = game['genre'].tolist()

game_new = pd.DataFrame({
    'id' : game_ids,
    'game_name' : game_name,
    'genre' : game_genre
})

game_new

"""Untuk mempermudah penulisan kode, nama data *final_ratings* diubah menjadi df"""

df = final_ratings

"""Melakukan proses encoding fitur *user_id* dan *game_id* ke dalam indeks integer"""

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = df['user_id'].unique().tolist()
print('list user_id: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

# Mengubah game_id menjadi list tanpa nilai yang sama
game_ids = df['game_id'].unique().tolist()

# Melakukan proses encoding game_id
game_to_game_encoded = {x: i for i, x in enumerate(game_ids)}

# Melakukan proses encoding angka ke game_id
game_encoded_to_game = {i: x for i, x in enumerate(game_ids)}

"""Selanjutnya memetkan *user_id* dan *game_id* ke *data frame* yang berkaitan"""

# Mapping user_id ke dataframe user
df['user'] = df['user_id'].map(user_to_user_encoded)

# Mapping game_id ke dataframe game
df['game'] = df['game_id'].map(game_to_game_encoded)

"""Melakukan pengecekan jumlah *user*, jumlah *game*, dan mengubah nilai rating menjadi *float*"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah game
num_game = len(game_encoded_to_game)
print(num_game)

# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of Game: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_game, min_rating, max_rating
))

"""####- Membagi data Training dan Validasi

Sebelum membagi data, acak data terlebih dahulu agar distribusinya menjadi *random*


"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Data train dan validasi dibagi dengan komposisi 80:20.

Namun sebelumnya, perlu dilakukan pememetaan *(mapping)* data user dan game agar menjadi satu value terlebih dahulu. Lalu, buatlah rating dalam skala 0 sampai 1 agar mudah dalam melakukan proses training.
"""

# Membuat variabel x untuk mencocokkan data user dan game menjadi satu value
x = df[['user', 'game']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""####- Training Model

Pada tahap ini, model menghitung skor kecocokan antara pengguna dan *game* dengan teknik *embedding*. Pertama, dilakukan proses *embedding* terhadap data user dan resto. Selanjutnya, melakukan operasi perkalian *dot product* antara *embedding* *user* dan *game*. Selain itu, ditambahkan bias untuk setiap *user* dan *game*. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi *sigmoid*.

Dibuatkan *class RecommenderNet* dengan *keras Model class*. Kode *class RecommenderNet* ini terinspirasi dari tutorial dalam situs Keras dengan beberapa adaptasi sesuai kasus yang sedang diselesaikan.
"""

from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_game, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_game = num_game
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.game_embedding = layers.Embedding( # layer embeddings game
        num_game,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.game_bias = layers.Embedding(num_game, 1) # layer embedding game bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    game_vector = self.game_embedding(inputs[:, 1]) # memanggil layer embedding 3
    game_bias = self.game_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_game = tf.tensordot(user_vector, game_vector, 2)

    x = dot_user_game + user_bias + game_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Selanjutnya, melakukan proses compile terhadap model."""

model = RecommenderNet(num_users, num_game, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan *Binary Crossentropy* untuk menghitung *loss function*, *Adam (Adaptive Moment Estimation)* sebagai *optimizer*, dan *root mean squared error (RMSE)* sebagai *metrics evaluation*.

Langkah berikutnya, adalah memulai proses training.
"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 30,
    validation_data = (x_val, y_val)
)

"""###- Visualisasi Metrik

Untuk melihat visualisasi proses training, dilakukan plot metrik evaluasi dengan matplotlib.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

plt.savefig('Model_metrics.png')
plt.show()

"""proses training model cukup smooth pada iterasi ke 30 belum terlihat bahwa model konvergen.Dari proses ini, kita memperoleh nilai error akhir sebesar sekitar 0.3721 dan error pada data validasi sebesar 0.6663. Nilai tersebut cukup bagus untuk sistem rekomendasi.

####- Mendapatkan Rekomendasi Game

Untuk mendapatkan rekomendasi game, pertama ambil sampel *user* secara acak dan definisikan variabel *game_not_played* yang merupakan daftar *game* yang belum pernah dimainkan oleh pengguna. Tujuan variabel *game_not_played* ini ditentukan, karena daftar *game_not_played* inilah yang akan menjadi *game* yang akan direkomendasikan.

Sebelumnya, pada data *user* dapat diketahui *game* apa saja yang telah dimainkan oleh pengguna beserta dengan jumlah Jam bermainnya. Jumlah jam bermain yang kemudian dikonversi menjadi rating digunakan untuk membuat rekomendasi *game* yang mungkin cocok untuk pengguna. *Game* yang akan direkomendasikan tentulah *game* yang belum pernah dimainkan oleh pengguna. Oleh karena itu, perlu dibuatkan variabel *game_not_played* sebagai daftar *game* untuk direkomendasikan pada pengguna.

Variabel *game_not_played* diperoleh dengan menggunakan operator bitwise (~) pada variabel *game_played_by_user*.
"""

game_df = game_new
df = final_ratings

# Mengambil sample user
user_ids = df.user_id.sample(1).iloc[0]
game_played_by_user = df[df.user_id == user_ids]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
game_not_played = game_df[~game_df['id'].isin(game_played_by_user.game_id.values)]['id']
game_not_played = list(
    set(game_not_played)
    .intersection(set(game_to_game_encoded.keys()))
)

game_not_played = [[game_to_game_encoded.get(x)] for x in game_not_played]
user_encoder = user_to_user_encoded.get(user_ids)
user_game_array = np.hstack(
    ([[user_encoder]] * len(game_not_played), game_not_played)
)

ratings = model.predict(user_game_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_game_ids = [
    game_encoded_to_game.get(game_not_played[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_ids))
print('===' * 9)
print('Game with high playing hours from user')
print('----' * 8)

top_game_user = (
    game_played_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .game_id.values
)

game_df_rows = game_df[game_df['id'].isin(top_game_user)].drop_duplicates(subset=['game_name'])
for row in game_df_rows.itertuples():
    print(row.game_name, ':', row.genre)

print('----' * 8)
print('Top 10 game recommendation')
print('----' * 8)

recommended_game = game_df[game_df['id'].isin(recommended_game_ids)].drop_duplicates(subset=['game_name'])
for row in recommended_game.itertuples():
    print(row.game_name, ':', row.genre)

"""##6. *Evaluation*

###- Content Based Filtering - based on Genre

Untuk mengukur seberapa baik model, digunakan metrik evaluasi. Adapun metrik yang sebagai alat ukur perfoma model yang dibuat antara lain ***Precission***

- Presisi adalah metrik yang digunakan untuk mengevaluasi kinerja model pengelompokan. Metrik ini menghitung rasio prediksi positif sejati terhadap jumlah total prediksi positif (positif sejati dan positif palsu).

Rumus dari presisi adaalah sebagai berikut:

$$ Precision = \dfrac {TP}  {(TP + FP)} $$

dimana
- TP (True Positives) adalah jumlah kejadian positif yang diprediksi dengan benar.
- FP (False Positif) adalah jumlah kejadian positif yang diprediksi salah.

Adapun interpretasi hasil presisi berdasarkan Tabel 15, 16, dan 17 dapat dilihat bahwasanya besar presisi jika dihitung dengan menggunakan rumusan presisi adalah 5/5 atau 100% untuk model rekomendasi Top-5. Hal ini menunjukkan bahwa model mampu memberikan rekomendasi dengan tingkat presisi yang sangat baik (dalam hal ini 100%). Hal ini sesuai dengan hasil uji dimana model mampu memberikan rekomendasi dengan *Genre*, *Popular Tags*, dan *Game Details* yang yang mirip dengan game "Portal 2" yaitu dengan Genres: Education, Type: Free dan Content Rating: Everyone. Hasil rekomendasi menampilkan 5 buah *game* dengan Genres: *Action* dan *Adventure*, Popular Tags: *Puzzle,Co-op,First-Person,Sci-fi,Comedy* dan Game details: *Single-player dan Steam Achievements* yang serupa dengan "Portal 2".

####- Collaborative Filtering

Metrics yang digunakan untuk mengevaluasi kinerja dari *Collaborative Filtering* ini adalah *RMSE (Root-Mean Squared Error)*.

*Root mean square error* atau *root mean square deviation* salah satu ukuran yang paling umum digunakan untuk mengevaluasi kualitas prediksi. Ukuran ini menunjukkan seberapa jauh prediksi jatuh dari nilai sebenarnya yang diukur menggunakan jarak *Euclidean*.

Untuk menghitung RMSE, hitung residual (perbedaan antara prediksi dan kebenaran) untuk setiap titik data, hitung norma residual untuk setiap titik data, hitung rata-rata residual, dan ambil akar kuadrat dari rata-rata tersebut. RMSE biasanya digunakan dalam aplikasi *supervised learning*, karena RMSE menggunakan dan membutuhkan pengukuran yang sebenarnya pada setiap titik data yang diprediksi.

Root mean square error dapat dihitung dengan persamaan berikut:

$$RMSE = \sqrt {\frac{\sum_{i=1}^{N} || y(i) - \hat{y}(i) ||^2}{N}}$$

di mana N adalah jumlah titik data, y(i) adalah pengukuran ke-i, dan y ̂(i) adalah prediksi yang sesuai.
"""

from sklearn.metrics import mean_squared_error

y_pred = model.predict(x_val)

print("RMSE =", mean_squared_error(y_val, y_pred, squared=False))

"""Nilai RMSE dari model jika dibandingkan dengan data validasi adalah 0.42014. Nilai RMSE cukup rendah, hal ini menunjukkan bahwa model memiliki akurasi yang cukup baik dalam memberikan rekomendasi dengan pendekatan *Collaborative Filtering*"""